{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Leveraging Delta Lake with Synapse Analytics\r\n",
        "\r\n",
        "This Python notebook will showcase levering delta lake capabilities inside a Synapse Spark Pool.  As the link below highlights, we can also leverage streaming data with delta lake\r\n",
        "\r\n",
        "https://docs.microsoft.com/en-us/azure/synapse-analytics/spark/apache-spark-delta-lake-overview?pivots=programming-language-python\r\n",
        "\r\n",
        "Another great resource\r\n",
        "https://docs.delta.io/latest/api/python/index.html\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\r\n",
        "\r\n",
        "#if you want to go to a the default path, use relative value, else provide a location in data lake\r\n",
        "\r\n",
        "session_id = random.randint(0,1000000)\r\n",
        "delta_table_path = \"/delta/delta-table-{0}\".format(session_id)\r\n",
        "delta_table_path = \"abfss://delta-example@mmxsynanapsexadlsge2.dfs.core.windows.net/delta/delta-table-{0}\".format(session_id)\r\n",
        "delta_table_path"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 23,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:43:23.4057582Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:43:23.4963736Z",
              "execution_finish_time": "2021-09-14T16:43:23.6542617Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 23, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "'abfss://delta-example@mmxsynanapsexadlsge2.dfs.core.windows.net/delta/delta-table-899014'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.range(0,5)\r\n",
        "data.show()\r\n",
        "data.write.format(\"delta\").save(delta_table_path)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 24,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:43:29.3106408Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:43:29.4050351Z",
              "execution_finish_time": "2021-09-14T16:43:32.1814851Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 24, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"delta\").load(delta_table_path)\r\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 25,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:43:33.870175Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:43:33.9551612Z",
              "execution_finish_time": "2021-09-14T16:43:35.014931Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 25, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n|  1|\n|  2|\n|  4|\n|  3|\n|  0|\n+---+"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Update table table\r\n",
        "Delta Lake Supports several operations to modify tables using standard DAtaFrame APIs, this is one of the big enhancements that delta format added"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = spark.range(5,10)\r\n",
        "data.write.format(\"delta\").mode(\"overwrite\").save(delta_table_path)\r\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 26,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:43:37.4260458Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:43:38.0557961Z",
              "execution_finish_time": "2021-09-14T16:43:41.93077Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 26, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n|  7|\n|  5|\n|  6|\n|  8|\n|  9|\n+---+"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save as catalog tables\r\n",
        "Delta Lake can write to managed or external catalog tables."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.write.format(\"delta\").saveAsTable(\"ManagedDeltaTable\")\r\n",
        "spark.sql(\"CREATE TABLE ExternalDeltaTable USING DELTA LOCATION '{0}'\".format(delta_table_path))\r\n",
        "spark.sql(\"SHOW TABLES\").show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 6,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:26:01.5444877Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:26:01.6323923Z",
              "execution_finish_time": "2021-09-14T16:26:16.2474407Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 6, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------------------+-----------+\n|database|         tableName|isTemporary|\n+--------+------------------+-----------+\n| default| manageddeltatable|      false|\n| default|externaldeltatable|      false|\n+--------+------------------+-----------+"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this code, you created a new table in the catalog from an existing data frame - referred to as a managed table.  Then you defined a new external table in the catalog that uses an existing location - referred to as an external table.  In the ouput you see both tables - no matter how they were created - they are listed in teh catalog.\r\n",
        "\r\n",
        "Now lets look at the extended properites of bot of these tables"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DESCRIBE EXTENDED ManagedDeltaTable\").show(truncate=False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 17,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:37:02.5302075Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:37:02.6175037Z",
              "execution_finish_time": "2021-09-14T16:37:03.1118356Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 17, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-------+\n|col_name                    |data_type                                                                                                                            |comment|\n+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-------+\n|id                          |bigint                                                                                                                               |null   |\n|                            |                                                                                                                                     |       |\n|# Detailed Table Information|                                                                                                                                     |       |\n|Database                    |default                                                                                                                              |       |\n|Table                       |manageddeltatable                                                                                                                    |       |\n|Owner                       |trusted-service-user                                                                                                                 |       |\n|Created Time                |Tue Sep 14 16:26:14 UTC 2021                                                                                                         |       |\n|Last Access                 |Thu Jan 01 00:00:00 UTC 1970                                                                                                         |       |\n|Created By                  |Spark 2.4.4.2.6.99.201-42194453                                                                                                      |       |\n|Type                        |MANAGED                                                                                                                              |       |\n|Provider                    |delta                                                                                                                                |       |\n|Table Properties            |[transient_lastDdlTime=1631636774]                                                                                                   |       |\n|Location                    |abfss://mmsynapsexfilesystem@mmxsynanapsexadlsge2.dfs.core.windows.net/synapse/workspaces/mm-synapse-base/warehouse/manageddeltatable|       |\n|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                                                                                   |       |\n|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                                                                                     |       |\n|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat                                                                            |       |\n|Storage Properties          |[serialization.format=1]                                                                                                             |       |\n+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------+-------+"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DESCRIBE EXTENDED ExternalDeltaTable\").show(truncate=False)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 8,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:29:08.6362991Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:29:08.7379004Z",
              "execution_finish_time": "2021-09-14T16:29:09.2211783Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 8, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------+---------------------------------------------------------------------+-------+\n|col_name                    |data_type                                                            |comment|\n+----------------------------+---------------------------------------------------------------------+-------+\n|id                          |bigint                                                               |null   |\n|                            |                                                                     |       |\n|# Detailed Table Information|                                                                     |       |\n|Database                    |default                                                              |       |\n|Table                       |externaldeltatable                                                   |       |\n|Owner                       |trusted-service-user                                                 |       |\n|Created Time                |Tue Sep 14 16:26:15 UTC 2021                                         |       |\n|Last Access                 |Thu Jan 01 00:00:00 UTC 1970                                         |       |\n|Created By                  |Spark 2.4.4.2.6.99.201-42194453                                      |       |\n|Type                        |EXTERNAL                                                             |       |\n|Provider                    |DELTA                                                                |       |\n|Table Properties            |[transient_lastDdlTime=1631636775]                                   |       |\n|Location                    |abfss://delta-example@mmxsynanapsexadlsge2.dfs.core.windows.net/delta|       |\n|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                   |       |\n|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                     |       |\n|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat            |       |\n|Storage Properties          |[serialization.format=1]                                             |       |\n+----------------------------+---------------------------------------------------------------------+-------+"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conditional update without overview\r\n",
        "\r\n",
        "Delta Lake provides programmcatic APIS to conditional update, delete, and merge (aka - an upsert) data into tables"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from delta.tables import *\r\n",
        "from pyspark.sql.functions import *\r\n",
        "\r\n",
        "delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
        "\r\n",
        "delta_table.update(\r\n",
        "  condition = expr(\"id % 2 == 0\"),\r\n",
        "  set = { \"id\": expr(\"id + 100\") })\r\n",
        "delta_table.toDF().show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 9,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:30:18.2160486Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:30:18.3166094Z",
              "execution_finish_time": "2021-09-14T16:30:23.5422132Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 9, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n|  9|\n|106|\n|108|\n|  5|\n|  7|\n+---+"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete Rows\r\n",
        "Let's leverage delta to delete rows"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delta_table.delete(\"id % 2 == 0\")\r\n",
        "delta_table.toDF().show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 10,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:31:18.6220636Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:31:18.7231659Z",
              "execution_finish_time": "2021-09-14T16:31:22.6300718Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 10, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n|  9|\n|  5|\n|  7|\n+---+"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The existing data has been assigned the value -1 in the update(WhenMatched) code path. The new data that was created at the top of the snippet and was added via the insert code path (WhenNotMatched), was also added."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data = spark.range(0,20).alias(\"newData\")\r\n",
        "\r\n",
        "delta_table.alias(\"oldData\")\\\r\n",
        "    .merge(new_data.alias(\"newData\"), \"oldData.id = newData.id\")\\\r\n",
        "    .whenMatchedUpdate(set = { \"id\": lit(\"-1\")})\\\r\n",
        "    .whenNotMatchedInsert(values = { \"id\": col(\"newData.id\") })\\\r\n",
        "    .execute()\r\n",
        "\r\n",
        "delta_table.toDF().show(100)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 11,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:32:51.0806167Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:32:51.1778464Z",
              "execution_finish_time": "2021-09-14T16:33:01.680383Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 11, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n| 15|\n|  1|\n| 13|\n|  2|\n| 10|\n|  4|\n|  0|\n|  3|\n| 11|\n| -1|\n| 17|\n| 12|\n| 14|\n| 18|\n|  6|\n| 19|\n|  8|\n| -1|\n| 16|\n| -1|\n+---+"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### History\r\n",
        "Delta Lake has the ability to allow looing into history of a table.  That is, the changes that were made to the underlying Delta Table.  Let's inspect the history"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display(delta_table.history().show(20, 1000, False))"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 15,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:35:46.8733621Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:35:46.9657497Z",
              "execution_finish_time": "2021-09-14T16:35:48.0239745Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 15, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------+--------+---------+-------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|version|          timestamp|userId|userName|operation|                                                operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|                                                                                                                                                                                              operationMetrics|\n+-------+-------------------+------+--------+---------+-------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|      4|2021-09-14 16:32:56|  null|    null|    MERGE|                       [predicate -> (oldData.`id` = newData.`id`)]|null|    null|     null|          3|          null|        false|[numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 21, numTargetRowsInserted -> 17, numTargetRowsUpdated -> 3, numOutputRows -> 20, numSourceRows -> 20, numTargetFilesRemoved -> 3]|\n|      3|2021-09-14 16:31:20|  null|    null|   DELETE|[predicate -> [\"((`id` % CAST(2 AS BIGINT)) = CAST(0 AS BIGINT))\"]]|null|    null|     null|          2|          null|        false|                                                                                                                           [numRemovedFiles -> 2, numDeletedRows -> 2, numAddedFiles -> 1, numCopiedRows -> 0]|\n|      2|2021-09-14 16:30:20|  null|    null|   UPDATE| [predicate -> ((id#499L % cast(2 as bigint)) = cast(0 as bigint))]|null|    null|     null|          1|          null|        false|                                                                                                                           [numRemovedFiles -> 2, numAddedFiles -> 2, numUpdatedRows -> 2, numCopiedRows -> 0]|\n|      1|2021-09-14 16:24:19|  null|    null|    WRITE|                             [mode -> Overwrite, partitionBy -> []]|null|    null|     null|          0|          null|        false|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n|      0|2021-09-14 16:23:13|  null|    null|    WRITE|                         [mode -> ErrorIfExists, partitionBy -> []]|null|    null|     null|       null|          null|         true|                                                                                                                                                   [numFiles -> 6, numOutputBytes -> 2407, numOutputRows -> 5]|\n+-------+-------------------+------+--------+---------+-------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read older versions of data using Time Travel\r\n",
        "\r\n",
        "It's possible to query previous snapshots of your Delta Lake table by using a feature called Time Travel. If you want to access the data that you overwrote, you can query a snapshot of the table before you overwrote the first set of data using the versionAsOf option.\r\n",
        "\r\n",
        "Once you run the cell below, you should see the first set of data from before you overwrote it. Time Travel is an extremely powerful feature that takes advantage of the power of the Delta Lake transaction log to access data that is no longer in the table. Removing the version 0 option (or specifying version 1) would let you see the newer data again. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(delta_table_path)\r\n",
        "df.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 18,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:38:06.6343366Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:38:06.7525725Z",
              "execution_finish_time": "2021-09-14T16:38:12.0245302Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 18, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n| id|\n+---+\n|  1|\n|  2|\n|  3|\n|  4|\n|  0|\n+---+"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"DESCRIBE HISTORY delta.`{0}`\".format(delta_table_path)).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 19,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:39:28.016054Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:39:28.1193681Z",
              "execution_finish_time": "2021-09-14T16:39:29.9190579Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 19, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+\n|version|          timestamp|userId|userName|operation| operationParameters| job|notebook|clusterId|readVersion|isolationLevel|isBlindAppend|    operationMetrics|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+\n|      4|2021-09-14 16:32:56|  null|    null|    MERGE|[predicate -> (ol...|null|    null|     null|          3|          null|        false|[numTargetRowsCop...|\n|      3|2021-09-14 16:31:20|  null|    null|   DELETE|[predicate -> [\"(...|null|    null|     null|          2|          null|        false|[numRemovedFiles ...|\n|      2|2021-09-14 16:30:20|  null|    null|   UPDATE|[predicate -> ((i...|null|    null|     null|          1|          null|        false|[numRemovedFiles ...|\n|      1|2021-09-14 16:24:19|  null|    null|    WRITE|[mode -> Overwrit...|null|    null|     null|          0|          null|        false|[numFiles -> 6, n...|\n|      0|2021-09-14 16:23:13|  null|    null|    WRITE|[mode -> ErrorIfE...|null|    null|     null|       null|          null|         true|[numFiles -> 6, n...|\n+-------+-------------------+------+--------+---------+--------------------+----+--------+---------+-----------+--------------+-------------+--------------------+"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vacuum Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"VACUUM delta.`{0}`\".format(delta_table_path)).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": "mmsparkpool",
              "session_id": 10,
              "statement_id": 20,
              "state": "finished",
              "livy_statement_state": "available",
              "queued_time": "2021-09-14T16:40:30.7374269Z",
              "session_start_time": null,
              "execution_start_time": "2021-09-14T16:40:30.8581506Z",
              "execution_finish_time": "2021-09-14T16:40:34.7542627Z"
            },
            "text/plain": "StatementMeta(mmsparkpool, 10, 20, Finished, Available)"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n|                path|\n+--------------------+\n|abfss://delta-exa...|\n+--------------------+"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}